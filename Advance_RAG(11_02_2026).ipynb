!pip install -q pdfplumber
!pip install -q  langchain-text-splitters

from google.colab import files
import pdfplumber
import sys # Import sys for SystemExit
from langchain_text_splitters import RecursiveCharacterTextSplitter

print("Upload your PDF file")
uploaded = files.upload()

if not uploaded:
    print("No file was uploaded. Please upload a PDF file to proceed.", file=sys.stderr)
    raise SystemExit("No file uploaded.")

pdf_file = list(uploaded.keys())[0]

def extract_text_from_pdf(pdf_path):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text
    except pdfplumber.pdf.PdfminerException as e:
        print(f"Error: The file '{pdf_path}' could not be processed as a PDF. It might be corrupted or not a PDF file. Original error: {e}", file=sys.stderr)
        return None

pdf_text = extract_text_from_pdf(pdf_file)

if pdf_text is not None:
    print("\nPDF Text Extracted Successfully\n")
    print(pdf_text[:2000])

    # Define chunking parameters
    chunk_size = 1000 # Number of characters in each chunk
    chunk_overlap = 200 # Number of characters to overlap between chunks

    # Initialize the text splitter
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        add_start_index=True,
    )

    # Split the text into chunks
    chunks = text_splitter.create_documents([pdf_text])

    print(f"\nCreated {len(chunks)} chunks.")
    print("\n--- First 3 Chunks ---\n")
    for i, chunk in enumerate(chunks[:3]):
        print(f"Chunk {i+1} (Length: {len(chunk.page_content)}):\n{chunk.page_content[:500]}...\n")

else:
    print("\nFailed to extract text. Please ensure you uploaded a valid PDF file.")
